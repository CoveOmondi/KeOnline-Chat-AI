{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import openai\n",
    "from difflib import get_close_matches\n",
    "from flask import Flask, request, jsonify\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Install the openai library using pip\n",
    "# Step 2: Set up your OpenAI API credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5512\\1994507318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# Generate the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Check if the response is too short or contains a spelling correction suggestion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5512\\1994507318.py\u001b[0m in \u001b[0;36mgenerate_response\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Step 5: Define the function to generate the next response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     response = openai.Completion.create(\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"davinci\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         )\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             return (\n\u001b[1;32m--> 619\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "# Step 3: Load the CSV file into a list of dictionaries\n",
    "with open(\"FurnitureDealers.csv\", encoding='utf-8') as f:\n",
    "    businesses = [{k: v for k, v in row.items()} for row in csv.DictReader(f)]\n",
    "\n",
    "# Step 4: Define the function to retrieve information about a business\n",
    "def get_business_info(business_name):\n",
    "    matches = get_close_matches(business_name.lower(), [b[\"Business Name\"].lower() for b in businesses])\n",
    "    if matches:\n",
    "        business_name = matches[0]\n",
    "    else:\n",
    "        return f\"Sorry, I couldn't find any information about {business_name} in my database.\"\n",
    "\n",
    "    for business in businesses:\n",
    "        if business[\"Business Name\"].lower() == business_name:\n",
    "            return f\"{business['Business Name']} is located in {business['County']}. They are in the {business['Business Segment']} category. Contact information: {business['Main Phone']}\"\n",
    "    return f\"Sorry, I couldn't find any information about {business_name} in my database. You can add the business to our database by creating an account \"\n",
    "\n",
    "# Step 5: Define the function to generate the next response\n",
    "def generate_response(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=200,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        timeout=10,\n",
    "        context=conversation_history\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Step 6: Start the conversation\n",
    "conversation_history = []\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # End the conversation if the user says \"bye\"\n",
    "    if user_input.lower() == \"bye\":\n",
    "        break\n",
    "\n",
    "    # Check if the user is asking for information about a business\n",
    "    if \"tell me about\" in user_input.lower():\n",
    "        business_name = user_input.lower().replace(\"tell me about\", \"\").strip()\n",
    "        info = get_business_info(business_name)\n",
    "        prompt = f\"{info} \\nAI: \"\n",
    "\n",
    "    else:\n",
    "        # Generate the response\n",
    "        response = generate_response(user_input.strip())\n",
    "\n",
    "        # Check if the response is too short or contains a spelling correction suggestion\n",
    "        if len(response) < 5 or \"did you mean\" in response.lower():\n",
    "            # Come up with a creative response\n",
    "            prompt = f\"I'm sorry, I'm not sure I understand. {user_input.strip()} sounds like something a {get_close_matches(user_input.lower(), ['human', 'robot', 'dog', 'cat', 'alien', 'wizard'])[0]} might say. \\nAI: \"\n",
    "        else:\n",
    "            # Use the generated response as the prompt\n",
    "            prompt = f\"{response} \\nAI: \"\n",
    "\n",
    "    # Generate the response using the OpenAI API\n",
    "    response = generate_response(prompt)\n",
    "\n",
    "    # Add the response to the conversation history\n",
    "    conversation_history.append(response)\n",
    "\n",
    "    # Print the response\n",
    "    print(f\"AI: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# load data from CSV file\n",
    "data = []\n",
    "\n",
    "with open('data.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "# define function to search for businesses\n",
    "def search_business(query):\n",
    "    results = []\n",
    "    for business in data:\n",
    "        if query.lower() in business['business_name'].lower():\n",
    "            results.append(business)\n",
    "    return results\n",
    "\n",
    "# define route for chatbot\n",
    "@app.route('/chatbot', methods=['POST'])\n",
    "def chatbot():\n",
    "    # get user input from POST request\n",
    "    user_input = request.json['message']\n",
    "\n",
    "    # search for businesses\n",
    "    results = search_business(user_input)\n",
    "\n",
    "    # check if there are any results\n",
    "    if len(results) == 0:\n",
    "        response = \"I'm sorry, I couldn't find any businesses matching that name. Please try again.\"\n",
    "    else:\n",
    "        # format results as a string\n",
    "        response = \"Here are the businesses I found:\\n\\n\"\n",
    "        for business in results:\n",
    "            response += f\"{business['business_name']}\\n{business['location']}\\n{business['category']}\\n{business['contact_info']}\\n\\n\"\n",
    "\n",
    "    # return response as JSON\n",
    "    return jsonify({'message': response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cove\\AppData\\Local\\Temp\\ipykernel_14108\\1912883005.py\", line 65, in process_queue\n",
      "  File \"C:\\Users\\cove\\AppData\\Local\\Temp\\ipykernel_14108\\1912883005.py\", line 49, in generate_response\n",
      "NameError: name 'response' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\cove\\AppData\\Local\\Temp\\ipykernel_14108\\1912883005.py\", line 72, in process_queue\n",
      "AttributeError: 'Queue' object has no attribute 'Empty'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import threading\n",
    "import time\n",
    "import openai\n",
    "import csv\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Define the function to retrieve information about a business\n",
    "with open(\"FurnitureDealers.csv\", encoding='utf-8') as f:\n",
    "    businesses = [{k: v for k, v in row.items()} for row in csv.DictReader(f)]\n",
    "\n",
    "# Step 4: Define the function to retrieve information about a business\n",
    "def get_business_info(business_name):\n",
    "    matches = get_close_matches(business_name.lower(), [b[\"Business Name\"].lower() for b in businesses])\n",
    "    if matches:\n",
    "        business_name = matches[0]\n",
    "    else:\n",
    "        return f\"Sorry, I couldn't find any information about {business_name} in my database.\"\n",
    "\n",
    "    for business in businesses:\n",
    "        if business[\"Business Name\"].lower() == business_name:\n",
    "            return f\"{business['Business Name']} is located in {business['County']}. They are in the {business['Business Segment']} category. Contact information: {business['Main Phone']}\"\n",
    "    return f\"Sorry, I couldn't find any information about {business_name} in my database. You can add the business to our database by creating an account \"\n",
    "    \n",
    "    \n",
    "    # Add code to retrieve information about the business here\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "# Define the function to generate the next response\n",
    "def generate_response(prompt):\n",
    "    # Add code to generate the response using OpenAI API here\n",
    "    def generate_response(prompt):\n",
    "        response = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=200,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        timeout=10,\n",
    "        context=conversation_history\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "    pass\n",
    "\n",
    "# Define a function to process the queue\n",
    "def process_queue(queue):\n",
    "    while True:\n",
    "        try:\n",
    "            # Get the next item from the queue\n",
    "            item = queue.get(block=True, timeout=1)\n",
    "\n",
    "            # Call the API to get information about the business\n",
    "            business_name = item['Business Name']\n",
    "            info = get_business_info(business_name)\n",
    "\n",
    "            # Generate the response using the OpenAI API\n",
    "            prompt = f\"{info} \\nAI: \"\n",
    "            response = generate_response(prompt)\n",
    "\n",
    "            # Add the response to the conversation history\n",
    "            item['conversation_history'].append(response)\n",
    "\n",
    "            # Print the response\n",
    "            print(f\"AI: {response}\")\n",
    "        except queue.Empty:\n",
    "            # If the queue is empty, sleep for a while and try again\n",
    "            time.sleep(1)\n",
    "\n",
    "# Define a function to schedule an API call\n",
    "def schedule_api_call(queue, business_name, conversation_history):\n",
    "    # Add the business name and conversation history to a dictionary\n",
    "    item = {'Business Name': business_name, 'conversation_history': conversation_history}\n",
    "\n",
    "    # Add the dictionary to the queue\n",
    "    queue.put(item)\n",
    "\n",
    "# Create a queue object\n",
    "queue = queue.Queue()\n",
    "\n",
    "# Start a thread to process the queue\n",
    "thread = threading.Thread(target=process_queue, args=(queue,))\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "# Example usage:\n",
    "business_name = \"Acme Inc.\"\n",
    "conversation_history = []\n",
    "\n",
    "# Schedule an API call\n",
    "schedule_api_call(queue, business_name, conversation_history)\n",
    "\n",
    "# Wait for a while to allow the API call to be processed\n",
    "time.sleep(5)\n",
    "\n",
    "# Print the conversation history\n",
    "print(conversation_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Location'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_604\\3664342028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"tell me about\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbusiness_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tell me about\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_business_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbusiness_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{info} \\nAI: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_604\\3664342028.py\u001b[0m in \u001b[0;36mget_business_info\u001b[1;34m(business_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbusiness\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbusinesses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbusiness\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Business Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbusiness_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;34mf\"{business['Business Name']} is located in {business['Location']}. They are in the {business['Business Segment']} category. Contact information: {business['Contact Info']}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34mf\"Sorry, I couldn't find any information about {business_name} in my database.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Location'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import openai\n",
    "import time\n",
    "import queue\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Load the CSV file into a list of dictionaries\n",
    "with open(\"FurnitureDealers.csv\", encoding=\"utf8\") as f:\n",
    "    businesses = [{k: v for k, v in row.items()} for row in csv.DictReader(f)]\n",
    "\n",
    "# Define the function to retrieve information about a business\n",
    "def get_business_info(business_name):\n",
    "    matches = get_close_matches(business_name.lower(), [b[\"Business Name\"].lower() for b in businesses])\n",
    "    if matches:\n",
    "        business_name = matches[0]\n",
    "    else:\n",
    "        return f\"Sorry, I couldn't find any information about {business_name} in my database.\"\n",
    "\n",
    "    for business in businesses:\n",
    "        if business[\"Business Name\"].lower() == business_name:\n",
    "            return f\"{business['Business Name']} is located in {business['Location']}. They are in the {business['Business Segment']} category. Contact information: {business['Contact Info']}\"\n",
    "    return f\"Sorry, I couldn't find any information about {business_name} in my database.\"\n",
    "\n",
    "# Define the function to generate the next response\n",
    "def generate_response(prompt, queue):\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"davinci\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.5,\n",
    "                max_tokens=200,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                timeout=10,\n",
    "                queue=queue,\n",
    "                wait_for_completion=False\n",
    "            )\n",
    "            return response.id\n",
    "        except openai.error.RateLimitError as e:\n",
    "            print(f\"OpenAI API rate limit exceeded, waiting {e.reset_after} seconds...\")\n",
    "            time.sleep(e.reset_after)\n",
    "\n",
    "# Start the conversation\n",
    "conversation_history = []\n",
    "queue = queue.Queue()\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # End the conversation if the user says \"bye\"\n",
    "    if user_input.lower() == \"bye\":\n",
    "        break\n",
    "\n",
    "    # Check if the user is asking for information about a business\n",
    "    if \"tell me about\" in user_input.lower():\n",
    "        business_name = user_input.lower().replace(\"tell me about\", \"\").strip()\n",
    "        info = get_business_info(business_name)\n",
    "        prompt = f\"{info} \\nAI: \"\n",
    "\n",
    "    else:\n",
    "        # Generate the response\n",
    "        response_id = generate_response(user_input.strip(), queue)\n",
    "        while True:\n",
    "            try:\n",
    "                response = openai.Completion.retrieve(\n",
    "                    response_id,\n",
    "                    queue=queue\n",
    "                )\n",
    "                break\n",
    "            except openai.error.InvalidRequestError:\n",
    "                pass\n",
    "\n",
    "        # Check if the response is too short or contains a spelling correction suggestion\n",
    "        if len(response.choices[0].text) < 5 or \"did you mean\" in response.choices[0].text.lower():\n",
    "            # Come up with a creative response\n",
    "            prompt = f\"I'm sorry, I'm not sure I understand. {user_input.strip()} sounds like something a {get_close_matches(user_input.lower(), ['human', 'robot', 'dog', 'cat', 'alien', 'wizard'])[0]} might say. \\nAI: \"\n",
    "        else:\n",
    "            # Use the generated response as the prompt\n",
    "            prompt = f\"{response.choices[0].text} \\nAI: \"\n",
    "\n",
    "    # Add the response to the conversation history\n",
    "    conversation_history.append(prompt)\n",
    "\n",
    "    # Print the response\n",
    "    print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to KeOnline GPT! An AI assistant that will help you get information about any business in Kenya\n",
      "You can ask me about any business by typing 'Tell me about [business name]'\n",
      "You can end the conversation at any time by typing 'bye'\n",
      "\n",
      "\n",
      "Nawal Centre is located in Mombasa. They are in the Shopping Centers category. Contact information: +254 702 477777 \n",
      "AI: Is there anything else you want to know?\n",
      "Nawal Centre is located in Mombasa. They are in the Shopping Centers category. Contact information: +254 702 477777 \n",
      "AI: Is there anything else you want to know?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'queue' has no attribute 'put'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11352\\2416760972.py\u001b[0m in \u001b[0;36mgenerate_response\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             response = openai.Completion.create(\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"davinci\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    225\u001b[0m         )\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    618\u001b[0m             return (\n\u001b[1;32m--> 619\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11352\\2416760972.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# Get the bot's response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mbot_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_bot_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m# Print the bot's response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11352\\2416760972.py\u001b[0m in \u001b[0;36mget_bot_response\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# Generate the response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;31m# Check if the response is too short or contains a spelling correction suggestion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11352\\2416760972.py\u001b[0m in \u001b[0;36mgenerate_response\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mopenai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRateLimitError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# wait for 5 minutes before retrying\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rate limit exceeded. Waiting for 5 minutes...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'queue' has no attribute 'put'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import csv\n",
    "import time\n",
    "import queue\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Set up the queue system\n",
    "api_queue = queue.Queue(maxsize=4)\n",
    "\n",
    "# Load the business data from the CSV file\n",
    "with open(\"FurnitureDealers.csv\", encoding=\"utf8\") as f:\n",
    "    businesses = [{k: v for k, v in row.items()} for row in csv.DictReader(f)]\n",
    "# Define a function to get business information by name\n",
    "def get_business_info(business_name):\n",
    "    matches = get_close_matches(business_name.lower(), [b[\"Business Name\"].lower() for b in businesses])\n",
    "    if matches:\n",
    "        business_name = matches[0]\n",
    "    else:\n",
    "        return f\"Sorry, I couldn't find any information about {business_name} in my database.\"\n",
    "\n",
    "    for business in businesses:\n",
    "        if business[\"Business Name\"].lower() == business_name:\n",
    "            return f\"{business['Business Name']} is located in {business['Locality']}. They are in the {business['Business Segment']} category. Contact information: {business['Main Phone']}\"\n",
    "    return f\"Sorry, I couldn't find any information about {business_name} in my database.\"\n",
    "\n",
    "# Define a function to generate a response from OpenAI API\n",
    "def generate_response(prompt):\n",
    "    # Wait for the API queue to have available slots\n",
    "    response = None\n",
    "    while response is None:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"davinci\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.5,\n",
    "                max_tokens=200,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                timeout=10,\n",
    "                context=conversation_history\n",
    "            )\n",
    "        except openai.error.RateLimitError as e:\n",
    "            queue.put(time.time() + 300) # wait for 5 minutes before retrying\n",
    "            print(\"Rate limit exceeded. Waiting for 5 minutes...\")\n",
    "            time.sleep(300)\n",
    "    \n",
    "\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Define a function to handle user input and generate a response\n",
    "def get_bot_response(user_input):\n",
    "    # End the conversation if the user says \"bye\"\n",
    "    if user_input.lower() == \"bye\":\n",
    "        return \"Goodbye!\"\n",
    "\n",
    "    # Check if the user is asking for information about a business\n",
    "    if \"tell me about\" in user_input.lower():\n",
    "        business_name = user_input.lower().replace(\"tell me about\", \"\").strip()\n",
    "        info = get_business_info(business_name)\n",
    "        if info is not None:\n",
    "            return f\"{info} \\nAI: Is there anything else you want to know?\"\n",
    "        else:\n",
    "            return f\"I'm sorry, I couldn't find any information about {business_name}. \\nAI: Is there anything else I can help you with?\"\n",
    "\n",
    "        \n",
    " \n",
    "\n",
    "    # Generate the response\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "    # Generate the response\n",
    "    response = generate_response(user_input.strip())\n",
    "\n",
    "    # Check if the response is too short or contains a spelling correction suggestion\n",
    "    if len(response) < 10 or \"did you mean\" in response.lower():\n",
    "        # Come up with a creative response\n",
    "        prompt = f\"I'm sorry, I'm not sure I understand. {user_input.strip()} sounds like something a {get_close_matches(user_input.lower(), ['human', 'robot', 'dog', 'cat', 'alien', 'wizard'])[0]} might say.\"\n",
    "        response = generate_response(prompt)\n",
    "\n",
    "    return f\"{response} \\nAI: Is there anything else I can help you with?\"\n",
    "\n",
    "# Start the conversation\n",
    "print(\"Welcome to KeOnline GPT! An AI assistant that will help you get information about any business in Kenya\")\n",
    "print(\"You can ask me about any business by typing 'Tell me about [business name]'\")\n",
    "print(\"You can end the conversation at any time by typing 'bye'\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Initialize the conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Keep the conversation going until the user says \"bye\"\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # Get the bot's response\n",
    "    bot_response = get_bot_response(user_input)\n",
    "\n",
    "    # Print the bot's response\n",
    "    print(bot_response)\n",
    "\n",
    "    # Add the conversation to the history\n",
    "    conversation_history.append((user_input, bot_response))\n",
    "\n",
    "    # Check if the user wants to see the conversation history\n",
    "    if \"history\" in user_input.lower():\n",
    "        print(\"Conversation History:\")\n",
    "        for i in range(len(conversation_history)):\n",
    "            print(f\"User: {conversation_history[i][0]}\")\n",
    "            print(f\"AI: {conversation_history[i][1]}\")\n",
    "\n",
    "    # Check if the user wants to clear the conversation history\n",
    "    if \"clear history\" in user_input.lower():\n",
    "        conversation_history.clear()\n",
    "        print(\"Conversation history cleared.\")\n",
    "\n",
    "    # Check if the response contains a question for the user\n",
    "    if \"?\" in bot_response:\n",
    "        # Wait for the user's response\n",
    "        while True:\n",
    "            user_input = input(\"User: \")\n",
    "            if user_input.lower() == \"bye\":\n",
    "                bot_response = \"Goodbye!\"\n",
    "                break\n",
    "            elif len(user_input) > 0:\n",
    "                break\n",
    "\n",
    "        # Generate a response to the user's input\n",
    "        bot_response = get_bot_response(user_input)\n",
    "        print(bot_response)\n",
    "\n",
    "        # Add the conversation to the history\n",
    "        conversation_history.append((user_input, bot_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
